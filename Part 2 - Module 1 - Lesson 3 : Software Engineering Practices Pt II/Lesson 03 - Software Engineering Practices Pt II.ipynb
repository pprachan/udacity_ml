{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software engineering practices part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding robustness with \n",
    "\n",
    "- Testing \n",
    "- Logging\n",
    "- Code reviews\n",
    "\n",
    "# Testing \n",
    "\n",
    "Skills to properly prepare code for an industry setting includes testing code\n",
    "- **Test driven development:** A development process where you write tests for tasks before writing the code to implement those tasks. \n",
    "- **Unit Test:** A type of test that covers a \"unit\" of code, usually a single function, independently from the rest of the program.\n",
    "\n",
    "Resources: \n",
    "\n",
    "- [Blog Post](https://www.predictiveanalyticsworld.com/patimes/four-ways-data-science-goes-wrong-and-how-test-driven-data-analysis-can-help/6947/)\n",
    "- Getting started Testing: [Slide Deck](https://speakerdeck.com/pycon2014/getting-started-testing-by-ned-batchelder) and [Presentation Vide](https://www.youtube.com/watch?v=FxSsnHeWQBY)\n",
    "\n",
    "#### Unit Tests\n",
    "\n",
    "- Test functions in a way that is repeatable and automated. \n",
    "- Ideally, we'd run a test program that runs all our unit tests and cleanly lets us know which ones failed and which ones succeeded. \n",
    "- Advantage: Unit tests are isolated from the rest of the program\n",
    "- Note that passing unit tests isn't always enough to prove that our program is working successfully. \n",
    "- [Integration Testing](https://www.fullstackpython.com/integration-testing.html)\n",
    "\n",
    "#### Unit Testing Tools \n",
    "\n",
    "- [pytest: Installation and getting started](https://docs.pytest.org/en/latest/getting-started.html)\n",
    "\n",
    "> **Task:** run `pytest` in command line to evaluate all files with `test_` \n",
    "\n",
    "Structure of the tests: \n",
    "\n",
    "- Write a function that has a specific task in one file\n",
    "```python\n",
    "def days_until_launch(current_day, launch_day):\n",
    "    return launch_day - current_day\n",
    "```\n",
    "- add another file which defines a new function in which there is an `assert` statement to test the function \n",
    "\n",
    "```python\n",
    "# import function to be tested\n",
    "from compute_launch import days_until_launch\n",
    "\n",
    "def test_days_until_launch_4():\n",
    "    assert(days_until_launch(22,26) == 4)\n",
    "```\n",
    "\n",
    "- run `pytest`in console.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Quiz : Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "### Workflow example ###\n",
    "\n",
    "# valid email\n",
    "def email_validator(email):\n",
    "    if email.count(\"@\") != 0 and email.count(\".\") != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# start testing\n",
    "print(email_validator(\"tmeiendresch@gmx.de\"))\n",
    "print(email_validator(\"tmeiendresch@gmx\"))\n",
    "print(email_validator(\"tmei@endresch@gmx..de\")) # <- wait!\n",
    "\n",
    "# ...Correct function to account for this error...\n",
    "\n",
    "# valid email v2\n",
    "def email_validator(email):\n",
    "    if email.count(\"@\") == 1 and email.count(\".\") == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# start testing v2\n",
    "print(email_validator(\"tmeiendresch@gmx.de\"))\n",
    "print(email_validator(\"tmeiendresch@gmx\"))\n",
    "print(email_validator(\"tmei@endresch@gmx..de\")) # <- wait!\n",
    "\n",
    "# ... and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def email_validator(email):\n",
    "    if email.count(\"@\") == 1 and email.count(\".\") == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def test_email_validator():\n",
    "    assert email_validator(\"tmeiendresch@gmx.de\")==True\n",
    "    assert email_validator(\"tmeiendresch@gmx\")==False\n",
    "    assert email_validator(\"tmei@endresch@gmx..de\")==False\n",
    "    print (\"Ok\")\n",
    "test_email_validator()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Driven Development and Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Driven Development:** Writing tests before you write the code that's being tested. Your test would fail at first, and you'll know you've finished implementing a task when this test passes. \n",
    "- Tests ought to check for all the differnt scenarios and edge cases you can think of, before even starting to write your function. \n",
    "- Run this test to get immediate feedback\n",
    "- When refactoring or adding to your code, tests help you rest assured that the rest of your code didn't break while you were making those changes. Test also helps ensure that your function behavior is repeatable, regardless of external parameters, such as hardware and time. \n",
    "\n",
    "Resources: \n",
    "\n",
    "- [Data Science TDD](https://www.linkedin.com/pulse/data-science-test-driven-development-sam-savage/)\n",
    "- [TDD for Data Science](http://engineering.pivotal.io/post/test-driven-development-for-data-science/)\n",
    "- [TDD is Essential for Good Data Science Here's Why](https://medium.com/@karijdempsey/test-driven-development-is-essential-for-good-data-science-heres-why-db7975a03a44)\n",
    "- [Testing your code](http://docs.python-guide.org/en/latest/writing/tests/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "> Logging is the process of recording messages to describe events that have occurred while running your software.\n",
    "\n",
    "Logging is valuable for understanding the events that occur while running your program. For example, if you run your model over night and see that it's producing ridiculous results the next day, log messages can really help you understand more about the context in which this occurred. Lets learn about the qualities that make a log message effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: Be professional and clear\n",
    "\n",
    "`Bad: Hmmm... this isn't working???\n",
    "Bad: idk.... :(\n",
    "Good: Couldn't parse file.`\n",
    "\n",
    "---\n",
    "\n",
    "Tip: Be concise and use normal capitalization\n",
    "\n",
    "`\n",
    "Bad: Start Product Recommendation Process\n",
    "Bad: We have completed the steps necessary and will now proceed with the recommendation process for the records in our product database.\n",
    "Good: Generating product recommendations.`\n",
    "\n",
    "---\n",
    "\n",
    "Tip: Choose the appropriate level for logging\n",
    "\n",
    "*DEBUG* - level you would use for anything that happens in the program.\n",
    "*ERROR* - level to record any error that occurs\n",
    "*INFO* - level to record all actions that are user-driven or system specific, such as regularly scheduled operations\n",
    "\n",
    "---\n",
    "\n",
    "Tip: Provide any useful information\n",
    "\n",
    "`\n",
    "Bad: Failed to read location data\n",
    "Good: Failed to read location data: store_id 8324971\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
